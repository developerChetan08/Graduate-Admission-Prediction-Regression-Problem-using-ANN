{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ab344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://www.kaggle.com/datasets/mohansacharya/graduate-admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d48c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2193ac15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Admission_Predict.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "783c6dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd7ea226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         400 non-null    int64  \n",
      " 1   GRE Score          400 non-null    int64  \n",
      " 2   TOEFL Score        400 non-null    int64  \n",
      " 3   University Rating  400 non-null    int64  \n",
      " 4   SOP                400 non-null    float64\n",
      " 5   LOR                400 non-null    float64\n",
      " 6   CGPA               400 non-null    float64\n",
      " 7   Research           400 non-null    int64  \n",
      " 8   Chance of Admit    400 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 28.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5299c6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5660469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df1e71da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b677b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eddcc51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b050761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "395    0.82\n",
       "396    0.84\n",
       "397    0.91\n",
       "398    0.67\n",
       "399    0.95\n",
       "Name: Chance of Admit , Length: 400, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94132dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0860b92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>301</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>334</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>305</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>307</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>318</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "93         301           97                  2  3.0   3.0  7.88         1\n",
       "23         334          119                  5  5.0   4.5  9.70         1\n",
       "299        305          112                  3  3.0   3.5  8.65         0\n",
       "13         307          109                  3  4.0   3.0  8.00         1\n",
       "90         318          106                  2  4.0   4.0  7.92         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "235        326          111                  5  4.5   4.0  9.23         1\n",
       "37         300          105                  1  1.0   2.0  7.80         0\n",
       "\n",
       "[320 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25bb9087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>324</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>299</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>316</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>300</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>309</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>305</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "125        300          100                  3  2.0   3.0  8.66         1\n",
       "328        324          112                  4  4.0   3.5  8.77         1\n",
       "339        324          107                  5  3.5   4.0  8.66         1\n",
       "172        322          110                  4  4.0   5.0  9.13         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "347        299           94                  1  1.0   1.0  7.34         0\n",
       "41         316          105                  2  2.5   2.5  8.20         1\n",
       "180        300          104                  3  3.5   3.0  8.16         0\n",
       "132        309          105                  5  3.5   3.5  8.56         0\n",
       "224        305          105                  2  3.0   2.0  8.23         0\n",
       "\n",
       "[80 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a1a3c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93     0.44\n",
       "23     0.95\n",
       "299    0.71\n",
       "13     0.62\n",
       "90     0.64\n",
       "       ... \n",
       "255    0.79\n",
       "72     0.93\n",
       "396    0.84\n",
       "235    0.88\n",
       "37     0.58\n",
       "Name: Chance of Admit , Length: 320, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d67de5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398    0.67\n",
       "125    0.64\n",
       "328    0.80\n",
       "339    0.81\n",
       "172    0.86\n",
       "       ... \n",
       "347    0.42\n",
       "41     0.49\n",
       "180    0.71\n",
       "132    0.71\n",
       "224    0.67\n",
       "Name: Chance of Admit , Length: 80, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c185bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5d126dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22      , 0.17857143, 0.25      , ..., 0.42857143, 0.25      ,\n",
       "        1.        ],\n",
       "       [0.88      , 0.96428571, 1.        , ..., 0.85714286, 0.91911765,\n",
       "        1.        ],\n",
       "       [0.3       , 0.71428571, 0.5       , ..., 0.57142857, 0.53308824,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.70220588,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.74632353,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.22058824,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e9625cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44      , 0.34615385, 0.5       , 0.625     , 0.75      ,\n",
       "        0.65562914, 0.        ],\n",
       "       [0.2       , 0.23076923, 0.5       , 0.25      , 0.5       ,\n",
       "        0.61589404, 1.        ],\n",
       "       [0.68      , 0.69230769, 0.75      , 0.75      , 0.625     ,\n",
       "        0.65231788, 1.        ],\n",
       "       [0.68      , 0.5       , 1.        , 0.625     , 0.75      ,\n",
       "        0.61589404, 1.        ],\n",
       "       [0.64      , 0.61538462, 0.75      , 0.75      , 1.        ,\n",
       "        0.77152318, 1.        ],\n",
       "       [0.36      , 0.46153846, 0.5       , 0.5       , 0.5       ,\n",
       "        0.47682119, 0.        ],\n",
       "       [0.4       , 0.46153846, 0.25      , 0.625     , 0.375     ,\n",
       "        0.50662252, 0.        ],\n",
       "       [0.2       , 0.30769231, 0.25      , 0.125     , 0.25      ,\n",
       "        0.35430464, 0.        ],\n",
       "       [0.4       , 0.19230769, 0.25      , 0.125     , 0.25      ,\n",
       "        0.16556291, 0.        ],\n",
       "       [1.        , 0.69230769, 0.75      , 1.        , 0.875     ,\n",
       "        0.94701987, 1.        ],\n",
       "       [0.62      , 0.65384615, 0.75      , 0.75      , 0.75      ,\n",
       "        0.71854305, 1.        ],\n",
       "       [0.92      , 0.96153846, 0.75      , 0.875     , 0.75      ,\n",
       "        0.93377483, 1.        ],\n",
       "       [0.82      , 0.80769231, 1.        , 0.875     , 0.625     ,\n",
       "        0.84768212, 1.        ],\n",
       "       [0.5       , 0.38461538, 0.5       , 0.5       , 0.375     ,\n",
       "        0.50662252, 0.        ],\n",
       "       [0.66      , 0.38461538, 0.5       , 0.75      , 0.75      ,\n",
       "        0.54304636, 1.        ],\n",
       "       [0.44      , 0.61538462, 0.25      , 0.625     , 0.5       ,\n",
       "        0.57284768, 0.        ],\n",
       "       [0.68      , 0.61538462, 0.5       , 0.625     , 0.5       ,\n",
       "        0.8013245 , 1.        ],\n",
       "       [0.8       , 0.80769231, 1.        , 0.875     , 0.5       ,\n",
       "        0.8410596 , 1.        ],\n",
       "       [0.12      , 0.03846154, 0.25      , 0.5       , 0.25      ,\n",
       "        0.24503311, 1.        ],\n",
       "       [0.36      , 0.57692308, 0.25      , 0.5       , 0.75      ,\n",
       "        0.54635762, 0.        ],\n",
       "       [0.4       , 0.46153846, 0.75      , 0.125     , 0.375     ,\n",
       "        0.51655629, 0.        ],\n",
       "       [0.68      , 0.80769231, 0.5       , 0.625     , 0.5       ,\n",
       "        0.64900662, 1.        ],\n",
       "       [0.68      , 0.61538462, 0.75      , 0.875     , 0.75      ,\n",
       "        0.7781457 , 1.        ],\n",
       "       [0.82      , 0.88461538, 0.75      , 0.875     , 1.        ,\n",
       "        0.86754967, 1.        ],\n",
       "       [0.58      , 0.46153846, 0.5       , 0.75      , 0.5       ,\n",
       "        0.39735099, 1.        ],\n",
       "       [0.16      , 0.15384615, 0.25      , 0.75      , 0.5       ,\n",
       "        0.40728477, 0.        ],\n",
       "       [0.6       , 0.38461538, 0.5       , 0.625     , 0.875     ,\n",
       "        0.50993377, 1.        ],\n",
       "       [0.5       , 0.61538462, 0.25      , 0.625     , 0.5       ,\n",
       "        0.54966887, 1.        ],\n",
       "       [0.88      , 0.84615385, 0.75      , 0.75      , 0.625     ,\n",
       "        0.90728477, 1.        ],\n",
       "       [0.4       , 0.30769231, 0.5       , 0.625     , 0.75      ,\n",
       "        0.40397351, 1.        ],\n",
       "       [1.        , 1.        , 0.75      , 1.        , 1.        ,\n",
       "        0.89403974, 1.        ],\n",
       "       [0.48      , 0.34615385, 0.25      , 0.25      , 0.5       ,\n",
       "        0.46688742, 0.        ],\n",
       "       [0.64      , 0.61538462, 1.        , 0.875     , 0.75      ,\n",
       "        0.71854305, 0.        ],\n",
       "       [0.64      , 0.61538462, 0.5       , 0.625     , 0.5       ,\n",
       "        0.71523179, 1.        ],\n",
       "       [0.62      , 0.57692308, 0.5       , 0.5       , 0.75      ,\n",
       "        0.46357616, 1.        ],\n",
       "       [0.44      , 0.42307692, 0.5       , 0.25      , 0.5       ,\n",
       "        0.40397351, 1.        ],\n",
       "       [0.2       , 0.19230769, 0.        , 0.5       , 0.25      ,\n",
       "        0.        , 1.        ],\n",
       "       [0.48      , 0.46153846, 0.25      , 0.75      , 0.625     ,\n",
       "        0.48013245, 0.        ],\n",
       "       [0.8       , 0.84615385, 0.75      , 1.        , 0.875     ,\n",
       "        0.87748344, 1.        ],\n",
       "       [0.56      , 0.57692308, 0.        , 0.625     , 0.625     ,\n",
       "        0.76821192, 0.        ],\n",
       "       [0.74      , 0.73076923, 0.75      , 0.875     , 1.        ,\n",
       "        0.77483444, 0.        ],\n",
       "       [0.16      , 0.42307692, 0.5       , 0.625     , 0.75      ,\n",
       "        0.57615894, 0.        ],\n",
       "       [0.88      , 0.88461538, 1.        , 0.75      , 0.875     ,\n",
       "        0.75165563, 1.        ],\n",
       "       [0.28      , 0.42307692, 0.25      , 0.5       , 0.5       ,\n",
       "        0.46357616, 1.        ],\n",
       "       [0.9       , 0.88461538, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        ],\n",
       "       [0.58      , 0.34615385, 0.75      , 0.875     , 0.625     ,\n",
       "        0.61589404, 0.        ],\n",
       "       [0.6       , 0.53846154, 0.5       , 0.625     , 0.75      ,\n",
       "        0.54304636, 1.        ],\n",
       "       [0.7       , 0.69230769, 0.75      , 0.75      , 0.75      ,\n",
       "        0.72847682, 1.        ],\n",
       "       [0.3       , 0.42307692, 0.25      , 0.5       , 0.75      ,\n",
       "        0.44039735, 0.        ],\n",
       "       [0.36      , 0.34615385, 0.25      , 0.5       , 0.625     ,\n",
       "        0.55960265, 0.        ],\n",
       "       [0.7       , 0.69230769, 0.75      , 0.625     , 0.625     ,\n",
       "        0.70198675, 0.        ],\n",
       "       [0.12      , 0.19230769, 0.25      , 0.375     , 0.375     ,\n",
       "        0.40728477, 0.        ],\n",
       "       [0.68      , 0.65384615, 0.75      , 0.5       , 0.5       ,\n",
       "        0.73178808, 1.        ],\n",
       "       [0.56      , 0.61538462, 0.5       , 0.75      , 0.5       ,\n",
       "        0.66225166, 0.        ],\n",
       "       [0.4       , 0.5       , 0.5       , 0.625     , 0.625     ,\n",
       "        0.6192053 , 0.        ],\n",
       "       [0.92      , 0.92307692, 1.        , 0.875     , 0.75      ,\n",
       "        0.79139073, 1.        ],\n",
       "       [0.08      , 0.03846154, 0.        , 0.125     , 0.125     ,\n",
       "        0.2781457 , 0.        ],\n",
       "       [0.        , 0.38461538, 0.75      , 0.25      , 0.375     ,\n",
       "        0.21854305, 0.        ],\n",
       "       [0.72      , 0.30769231, 0.75      , 1.        , 1.        ,\n",
       "        0.64900662, 1.        ],\n",
       "       [0.64      , 0.61538462, 0.5       , 0.75      , 1.        ,\n",
       "        0.60927152, 1.        ],\n",
       "       [0.96      , 0.88461538, 0.75      , 0.625     , 0.875     ,\n",
       "        0.8807947 , 1.        ],\n",
       "       [0.52      , 0.5       , 0.25      , 0.625     , 0.625     ,\n",
       "        0.60927152, 1.        ],\n",
       "       [0.8       , 0.73076923, 1.        , 1.        , 0.75      ,\n",
       "        0.83112583, 1.        ],\n",
       "       [0.52      , 0.42307692, 0.5       , 0.5       , 0.625     ,\n",
       "        0.63907285, 0.        ],\n",
       "       [0.14      , 0.15384615, 0.25      , 0.375     , 0.5       ,\n",
       "        0.28807947, 0.        ],\n",
       "       [0.68      , 0.73076923, 0.75      , 0.875     , 0.75      ,\n",
       "        0.6589404 , 0.        ],\n",
       "       [0.78      , 0.65384615, 0.75      , 0.875     , 0.875     ,\n",
       "        0.78807947, 1.        ],\n",
       "       [0.6       , 0.38461538, 0.5       , 0.5       , 0.625     ,\n",
       "        0.64238411, 1.        ],\n",
       "       [0.32      , 0.42307692, 0.25      , 0.375     , 0.5       ,\n",
       "        0.47019868, 1.        ],\n",
       "       [0.42      , 0.5       , 0.75      , 0.875     , 0.875     ,\n",
       "        0.72847682, 1.        ],\n",
       "       [0.68      , 0.61538462, 0.75      , 0.5       , 0.625     ,\n",
       "        0.71854305, 1.        ],\n",
       "       [0.28      , 0.23076923, 0.75      , 0.125     , 0.375     ,\n",
       "        0.34437086, 0.        ],\n",
       "       [0.56      , 0.5       , 0.5       , 0.5       , 0.625     ,\n",
       "        0.48675497, 1.        ],\n",
       "       [0.34      , 0.42307692, 0.25      , 0.25      , 0.625     ,\n",
       "        0.43046358, 0.        ],\n",
       "       [0.74      , 0.65384615, 0.75      , 0.75      , 0.875     ,\n",
       "        0.72847682, 1.        ],\n",
       "       [0.18      , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.17880795, 0.        ],\n",
       "       [0.52      , 0.42307692, 0.25      , 0.375     , 0.375     ,\n",
       "        0.46357616, 1.        ],\n",
       "       [0.2       , 0.38461538, 0.5       , 0.625     , 0.5       ,\n",
       "        0.45033113, 0.        ],\n",
       "       [0.38      , 0.42307692, 1.        , 0.625     , 0.625     ,\n",
       "        0.58278146, 0.        ],\n",
       "       [0.3       , 0.42307692, 0.25      , 0.5       , 0.25      ,\n",
       "        0.47350993, 0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3aa00c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f6de734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4f8d61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64 (256.00 Byte)\n",
      "Trainable params: 64 (256.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "627f4787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b90bca7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 1.3186 - val_loss: 1.3571\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0718 - val_loss: 1.0988\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8573 - val_loss: 0.8868\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6958 - val_loss: 0.7086\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5561 - val_loss: 0.5682\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4454 - val_loss: 0.4589\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3637 - val_loss: 0.3705\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2981 - val_loss: 0.3013\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2449 - val_loss: 0.2488\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2049 - val_loss: 0.2073\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled,y_train,epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f67cfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.3185571432113647,\n",
       "  1.0718340873718262,\n",
       "  0.857264518737793,\n",
       "  0.6957737803459167,\n",
       "  0.5560941100120544,\n",
       "  0.4453679323196411,\n",
       "  0.3636508584022522,\n",
       "  0.29807522892951965,\n",
       "  0.24492496252059937,\n",
       "  0.20489856600761414],\n",
       " 'val_loss': [1.3570876121520996,\n",
       "  1.0987513065338135,\n",
       "  0.8867536783218384,\n",
       "  0.7085996866226196,\n",
       "  0.5681630373001099,\n",
       "  0.4589044749736786,\n",
       "  0.3704966902732849,\n",
       "  0.30131739377975464,\n",
       "  0.24878066778182983,\n",
       "  0.20731136202812195]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "563c04a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9614546 ],\n",
       "       [0.9367265 ],\n",
       "       [1.3210913 ],\n",
       "       [1.1700436 ],\n",
       "       [1.4855093 ],\n",
       "       [0.70548815],\n",
       "       [0.76611155],\n",
       "       [0.33109272],\n",
       "       [0.13567306],\n",
       "       [1.7441957 ],\n",
       "       [1.3561441 ],\n",
       "       [1.6529313 ],\n",
       "       [1.4560422 ],\n",
       "       [0.5399084 ],\n",
       "       [1.3488936 ],\n",
       "       [0.9697823 ],\n",
       "       [1.3862183 ],\n",
       "       [1.4259881 ],\n",
       "       [0.89432335],\n",
       "       [1.0732528 ],\n",
       "       [0.37226826],\n",
       "       [1.3180631 ],\n",
       "       [1.4701546 ],\n",
       "       [1.7101109 ],\n",
       "       [1.2149411 ],\n",
       "       [0.76199704],\n",
       "       [1.2684947 ],\n",
       "       [1.2876284 ],\n",
       "       [1.5197628 ],\n",
       "       [1.1351329 ],\n",
       "       [1.8175166 ],\n",
       "       [0.54762477],\n",
       "       [1.0321743 ],\n",
       "       [1.330053  ],\n",
       "       [1.169589  ],\n",
       "       [0.9077014 ],\n",
       "       [0.853574  ],\n",
       "       [0.94464904],\n",
       "       [1.7160164 ],\n",
       "       [1.2793787 ],\n",
       "       [1.3499665 ],\n",
       "       [1.0639703 ],\n",
       "       [1.4132107 ],\n",
       "       [1.1130214 ],\n",
       "       [1.7351315 ],\n",
       "       [0.8272015 ],\n",
       "       [1.2690089 ],\n",
       "       [1.3869622 ],\n",
       "       [0.935207  ],\n",
       "       [0.86475515],\n",
       "       [0.9192049 ],\n",
       "       [0.53789705],\n",
       "       [1.2039529 ],\n",
       "       [0.9602751 ],\n",
       "       [0.9552732 ],\n",
       "       [1.4835119 ],\n",
       "       [0.19326831],\n",
       "       [0.3414322 ],\n",
       "       [1.5132267 ],\n",
       "       [1.4928161 ],\n",
       "       [1.5056459 ],\n",
       "       [1.357371  ],\n",
       "       [1.5258561 ],\n",
       "       [0.81711686],\n",
       "       [0.5095482 ],\n",
       "       [1.1227052 ],\n",
       "       [1.5276158 ],\n",
       "       [1.2256414 ],\n",
       "       [1.0512041 ],\n",
       "       [1.4509658 ],\n",
       "       [1.2158033 ],\n",
       "       [0.2146558 ],\n",
       "       [1.1406908 ],\n",
       "       [0.70856994],\n",
       "       [1.4174552 ],\n",
       "       [0.00212952],\n",
       "       [1.0855017 ],\n",
       "       [0.76697445],\n",
       "       [0.7291978 ],\n",
       "       [0.6172166 ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73b062f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.80835026004"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879c3c0",
   "metadata": {},
   "source": [
    "# Improve Model:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6e47662",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6e6d5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120 (480.00 Byte)\n",
      "Trainable params: 120 (480.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41a0c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d15363e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 0.0453 - val_loss: 0.0452\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0386 - val_loss: 0.0378\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0330 - val_loss: 0.0325\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0282 - val_loss: 0.0291\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0246 - val_loss: 0.0254\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0218\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0191 - val_loss: 0.0194\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0173 - val_loss: 0.0180\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0154\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0136\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0124\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0069\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0035\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "220c5509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.045349519699811935,\n",
       "  0.03857540339231491,\n",
       "  0.03295839577913284,\n",
       "  0.028185756877064705,\n",
       "  0.02463364787399769,\n",
       "  0.021548498421907425,\n",
       "  0.019139572978019714,\n",
       "  0.01726512424647808,\n",
       "  0.01546100527048111,\n",
       "  0.014069627039134502,\n",
       "  0.012791176326572895,\n",
       "  0.011645272374153137,\n",
       "  0.010727707296609879,\n",
       "  0.009799611754715443,\n",
       "  0.008987155742943287,\n",
       "  0.008308496326208115,\n",
       "  0.007540359161794186,\n",
       "  0.0069847991690039635,\n",
       "  0.006494480185210705,\n",
       "  0.006271454971283674,\n",
       "  0.006003912538290024,\n",
       "  0.005816279910504818,\n",
       "  0.005716064944863319,\n",
       "  0.00559599231928587,\n",
       "  0.005501507315784693,\n",
       "  0.005424643866717815,\n",
       "  0.005326432175934315,\n",
       "  0.005239827558398247,\n",
       "  0.005188708659261465,\n",
       "  0.005120323970913887,\n",
       "  0.005110731348395348,\n",
       "  0.004986220505088568,\n",
       "  0.00503369327634573,\n",
       "  0.005003522615879774,\n",
       "  0.004991097375750542,\n",
       "  0.004955652169883251,\n",
       "  0.004871700890362263,\n",
       "  0.004863532725721598,\n",
       "  0.004800841677933931,\n",
       "  0.004774398636072874,\n",
       "  0.004750310909003019,\n",
       "  0.00471634604036808,\n",
       "  0.004712922964245081,\n",
       "  0.004688567947596312,\n",
       "  0.004681373480707407,\n",
       "  0.004667906556278467,\n",
       "  0.004610280506312847,\n",
       "  0.004617735277861357,\n",
       "  0.004593287594616413,\n",
       "  0.004587010946124792,\n",
       "  0.004557244945317507,\n",
       "  0.004612917546182871,\n",
       "  0.004566000774502754,\n",
       "  0.004502477124333382,\n",
       "  0.004488358274102211,\n",
       "  0.004471924621611834,\n",
       "  0.004466792568564415,\n",
       "  0.004468060564249754,\n",
       "  0.004453030880540609,\n",
       "  0.004423986654728651,\n",
       "  0.004408606328070164,\n",
       "  0.004432916175574064,\n",
       "  0.004407135304063559,\n",
       "  0.004425333812832832,\n",
       "  0.004431947134435177,\n",
       "  0.004355278797447681,\n",
       "  0.004342689178884029,\n",
       "  0.004373539239168167,\n",
       "  0.004318905528634787,\n",
       "  0.004310092888772488,\n",
       "  0.004318742081522942,\n",
       "  0.0043015507981181145,\n",
       "  0.0042941211722791195,\n",
       "  0.004270776640623808,\n",
       "  0.004304158966988325,\n",
       "  0.004222640302032232,\n",
       "  0.004236974287778139,\n",
       "  0.004234492778778076,\n",
       "  0.00425007613375783,\n",
       "  0.004235070664435625,\n",
       "  0.004206538666039705,\n",
       "  0.0042293863371014595,\n",
       "  0.004172631539404392,\n",
       "  0.004183335229754448,\n",
       "  0.004173332825303078,\n",
       "  0.004185931291431189,\n",
       "  0.00428103469312191,\n",
       "  0.004324331879615784,\n",
       "  0.004128162749111652,\n",
       "  0.00416816771030426,\n",
       "  0.004194824490696192,\n",
       "  0.004207802005112171,\n",
       "  0.004228704608976841,\n",
       "  0.004097983241081238,\n",
       "  0.004158716183155775,\n",
       "  0.004147482570260763,\n",
       "  0.00412822887301445,\n",
       "  0.004092032089829445,\n",
       "  0.004086893983185291,\n",
       "  0.004081448540091515],\n",
       " 'val_loss': [0.04515456408262253,\n",
       "  0.03777416795492172,\n",
       "  0.03254471346735954,\n",
       "  0.029067791998386383,\n",
       "  0.025437045842409134,\n",
       "  0.021787799894809723,\n",
       "  0.0194256454706192,\n",
       "  0.018014132976531982,\n",
       "  0.01535770669579506,\n",
       "  0.013580124825239182,\n",
       "  0.012395113706588745,\n",
       "  0.011089907959103584,\n",
       "  0.009663848206400871,\n",
       "  0.008839757181704044,\n",
       "  0.007683512754738331,\n",
       "  0.006856655236333609,\n",
       "  0.006687566172331572,\n",
       "  0.0058964211493730545,\n",
       "  0.005491080693900585,\n",
       "  0.00526676420122385,\n",
       "  0.0052124918438494205,\n",
       "  0.0050664241425693035,\n",
       "  0.004959453828632832,\n",
       "  0.0047887833788990974,\n",
       "  0.004626695066690445,\n",
       "  0.004571736790239811,\n",
       "  0.004538346081972122,\n",
       "  0.004466661252081394,\n",
       "  0.004389943554997444,\n",
       "  0.004343333654105663,\n",
       "  0.004322653170675039,\n",
       "  0.004311567172408104,\n",
       "  0.004239029251039028,\n",
       "  0.004288134630769491,\n",
       "  0.0042138067074120045,\n",
       "  0.004161572549492121,\n",
       "  0.00416240468621254,\n",
       "  0.004078696481883526,\n",
       "  0.00404301006346941,\n",
       "  0.004009641706943512,\n",
       "  0.004006179049611092,\n",
       "  0.003998108673840761,\n",
       "  0.0039503066800534725,\n",
       "  0.003927255980670452,\n",
       "  0.003927909303456545,\n",
       "  0.0038812393322587013,\n",
       "  0.0038911979645490646,\n",
       "  0.003870568238198757,\n",
       "  0.003865701612085104,\n",
       "  0.0038087167777121067,\n",
       "  0.003785716136917472,\n",
       "  0.003834695089608431,\n",
       "  0.0037844337057322264,\n",
       "  0.0038245029281824827,\n",
       "  0.003781244857236743,\n",
       "  0.00376523332670331,\n",
       "  0.003732126671820879,\n",
       "  0.003788987873122096,\n",
       "  0.003740659449249506,\n",
       "  0.0037470271345227957,\n",
       "  0.0036960819270461798,\n",
       "  0.0036911722272634506,\n",
       "  0.003749125637114048,\n",
       "  0.0037057949230074883,\n",
       "  0.003793698502704501,\n",
       "  0.003655156120657921,\n",
       "  0.0036616132128983736,\n",
       "  0.003643475938588381,\n",
       "  0.003716137260198593,\n",
       "  0.0036390498280525208,\n",
       "  0.0036219970788806677,\n",
       "  0.003699341556057334,\n",
       "  0.003637422574684024,\n",
       "  0.0036453367210924625,\n",
       "  0.0036078174598515034,\n",
       "  0.0036691550631076097,\n",
       "  0.003608044935390353,\n",
       "  0.003597332164645195,\n",
       "  0.0036678980104625225,\n",
       "  0.003581658471375704,\n",
       "  0.0036148298531770706,\n",
       "  0.003576994873583317,\n",
       "  0.0036329729482531548,\n",
       "  0.003590093459933996,\n",
       "  0.003591252723708749,\n",
       "  0.0036078558769077063,\n",
       "  0.003539206925779581,\n",
       "  0.00363508821465075,\n",
       "  0.00354217691347003,\n",
       "  0.003567051375284791,\n",
       "  0.0036710728891193867,\n",
       "  0.003504985012114048,\n",
       "  0.0036305503454059362,\n",
       "  0.003517872653901577,\n",
       "  0.0034947339445352554,\n",
       "  0.003617549780756235,\n",
       "  0.003507668152451515,\n",
       "  0.0035242028534412384,\n",
       "  0.003541857236996293,\n",
       "  0.003516671247780323]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7facb952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7337353 ],\n",
       "       [0.7050129 ],\n",
       "       [0.8195321 ],\n",
       "       [0.82500136],\n",
       "       [0.8627628 ],\n",
       "       [0.66303104],\n",
       "       [0.68356997],\n",
       "       [0.59251404],\n",
       "       [0.53573763],\n",
       "       [0.90180343],\n",
       "       [0.8390916 ],\n",
       "       [0.94381857],\n",
       "       [0.9106039 ],\n",
       "       [0.6716192 ],\n",
       "       [0.7152765 ],\n",
       "       [0.74274886],\n",
       "       [0.80628455],\n",
       "       [0.9001443 ],\n",
       "       [0.5003216 ],\n",
       "       [0.7309311 ],\n",
       "       [0.70548236],\n",
       "       [0.806311  ],\n",
       "       [0.8411912 ],\n",
       "       [0.9296702 ],\n",
       "       [0.6780719 ],\n",
       "       [0.5804753 ],\n",
       "       [0.7215772 ],\n",
       "       [0.72518766],\n",
       "       [0.90943795],\n",
       "       [0.6769061 ],\n",
       "       [0.95198625],\n",
       "       [0.6666285 ],\n",
       "       [0.8281841 ],\n",
       "       [0.78646016],\n",
       "       [0.7407986 ],\n",
       "       [0.6895384 ],\n",
       "       [0.5213138 ],\n",
       "       [0.69184625],\n",
       "       [0.91242254],\n",
       "       [0.8534634 ],\n",
       "       [0.8431244 ],\n",
       "       [0.6901632 ],\n",
       "       [0.9227291 ],\n",
       "       [0.68674004],\n",
       "       [0.9907099 ],\n",
       "       [0.72328055],\n",
       "       [0.7497581 ],\n",
       "       [0.84683096],\n",
       "       [0.66472423],\n",
       "       [0.6905767 ],\n",
       "       [0.7972846 ],\n",
       "       [0.5922446 ],\n",
       "       [0.82885665],\n",
       "       [0.74982226],\n",
       "       [0.71793467],\n",
       "       [0.92592674],\n",
       "       [0.5322946 ],\n",
       "       [0.5213662 ],\n",
       "       [0.7710119 ],\n",
       "       [0.79485714],\n",
       "       [0.9256398 ],\n",
       "       [0.7224799 ],\n",
       "       [0.899745  ],\n",
       "       [0.739096  ],\n",
       "       [0.5571584 ],\n",
       "       [0.79536587],\n",
       "       [0.8577865 ],\n",
       "       [0.73833126],\n",
       "       [0.68867207],\n",
       "       [0.8230418 ],\n",
       "       [0.8276346 ],\n",
       "       [0.5869355 ],\n",
       "       [0.72381514],\n",
       "       [0.66145176],\n",
       "       [0.8477922 ],\n",
       "       [0.49128938],\n",
       "       [0.6605266 ],\n",
       "       [0.6314125 ],\n",
       "       [0.74103945],\n",
       "       [0.6572728 ]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35ffa5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7612641676270959"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03fc804a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x216ae415490>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'],label=\"Loss\")\n",
    "plt.plot(history.history['val_loss'],label=\"Val Loss\")\n",
    "plt.title(\"Loss VS Val_Loss Comparison\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc607e37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
